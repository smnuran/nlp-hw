Feature Engineering
=

Before, you built a logistic regression system from scratch and tested it on
how well it could predict if an answer was correct.

In this homework, you're going to continue to improve the accuracy of such a system by creating
new features (but as we'll talk about in a moment, "accuracy" isn't exactly the best metric to use as our primary objective).

You will improve the classification by extracting useful information from
the guesses and generate better features for input into the *logistic
regression* classifier to do a better job of selecting whether a guess to a
question is correct.

In the code, a guess is generated by a "Guesser".  This is the
foundation of what you'll put into your classifier.  You need to decide whether to "buzz in" on that guess.  This decision is made by your classifer, the "Buzzer".  In a perfect world, every time your guess was correct, you'd buzz in and every time your guess was wrong you would not.  The initial code here is not perfect, so you're going to use feature engineering to improve that.

NOTE: Because the goal of this assignment is feature engineering, not
classification algorithms, you may not change the underlying algorithm. You
can change add to the guessed answers (e.g., to create a new feature), but you
may not swap out the class that's generating classes nor can you change the
classifier.

This assignment is structured in a way that approximates how classification
works in the real world: features are typically underspecified (or not
specified at all). You have to articulate the features you
need. You then compete against others to provide useful predictions.

It may seem straightforward, but do not start this at the last minute. There
are often many things that go wrong in testing out features, and you'll want
to make sure your features work well once you've found them.

Likewise, because this homework is not going to tell you exactly what
you need to do, you'll need to have understood many of the concepts
we've covered in the class.  The bare essentials are classifiers,
information retrieval, and feature engineering, but it may be helpful
to review our coverage of syntax, semantics, etc.

Getting Started
-

As usual, install the packages you need, perhaps in a virtual environment:

    python3 -m venv .venv
    .venv/bin/pip3 install -r requirements.txt

And if NLTK complains about missing stopwords, you can download them:

    python -m nltk.downloader stopwords

You'll also need to create a directory for the models you'll be
creating

     mkdir -p models

But before you get started, you need to understand the overall structure of the code:
 * A part of the question comes into the guesser (in the code, this is called a "run")
 * The guesser generates a "guess" that _could_ be an answer to the question
 * The buzzer then needs to determine if that guess is correct or not.  This is a classifier.  You're going to make that better by providing the buzzer with new features.

You will need to be creative here!  To get a sense of how you might go through the process, review the lecture on feature engineering here:
https://www.youtube.com/watch?v=IzKFgigocAg

How to add a feature?
-

First, get an idea of what you want to do.  After training the classifier,
look at your predictions on the dev set and see where they're going wrong.

1.  To add a feature, you need to create a new subclass of the Feature class
in ``features.py``.  This is important so that you can try out different
features by turning them on and off with the command line.

2.  Add code to instantiate the feature in ``params.py``.

3.  (Optionally) Change the API to feed in more information into the feature
generation process.  This would be necessary to capture temporal dynamics or
use, say, information from Wikipedia:
https://drive.google.com/file/d/1-AhjvqsoZ01gz7EMt5VmlCnVpsE96A5n/view?usp=sharing

To walk you through the process, let's create a new feature that encodes how
often the guess appeared in the training set.  The first step is to define the
class in ``features.py``.

	class FrequencyFeature:
	    def __init__(self, name):
		from eval import normalize_answer
		self.name = name
		self.counts = Counter()
		self.normalize = normalize_answer

	    def add_training(self, question_source):
		import json
		with gzip.open(question_source) as infile:
			questions = json.load(infile)
			for ii in questions:
			    self.counts[self.normalize(ii["page"])] += 1

	    def __call__(self, question, run, guess):
		   yield ("guess", log(1 + self.counts[self.normalize(guess)]))


Pay attention to the ``call`` function.  If you're not familiar with
the ``yield`` keyword:
https://realpython.com/introduction-to-python-generators/

One very easy way of adding features is to just yield something else
in a function that you already have.

These will be sent to a DictVectorizer, the first element of the tuple
is the feature name, the second element of the tuple is the feature
value (look at the ``featurize`` function in buzzer.py).

Now that you have a feature class, it needs to be loaded when you run
your code.  This happens in ``params.py``.  Now you can
add the feature name to the command line to turn it on.

    for ff in flags.features:
        if ff == "Length":
            from features import LengthFeature
            feature = LengthFeature(ff)
            buzzer.add_feature(feature)

        if ff == "Frequency":
            from features import FrequencyFeature
            feature = FrequencyFeature(ff)
            feature.add_training("../data/qanta.buzztrain.json.gz")
            buzzer.add_feature(feature)

Don't forget that you're training a classifier.  This classifier will
be turned into a "pickle" file and stored in the models directory.  So
let's train the classifier *without* that new feature.

    mkdir -p models
    python3 buzzer.py --guesser_type=Gpr --limit=50 \
      --GprGuesser_filename=../models/buzztrain_gpr_cache \
      --questions=../data/qanta.buzztrain.json.gz --buzzer_guessers Gpr \
      --LogisticBuzzer_filename=models/no_length --features ""
    Setting up logging
    INFO:root:Using device 'cuda' (cuda flag=False)
    INFO:root:Initializing guesser of type Gpr
    INFO:root:Loading Gpr guesser
    Loading buzzer
    INFO:root:Buzzer using run length 100
    INFO:root:Using device 'cuda' (cuda flag=False)
    INFO:root:Initializing guesser of type Gpr
    INFO:root:Loading Gpr guesser
    INFO:root:9310 entries added to cache
    INFO:root:9310 entries added to cache
    INFO:root:Adding Gpr to Buzzer (total guessers=1)
    Initializing features: ['']
    dataset: ../data/qanta.buzztrain.json.gz
    ERROR:root:1 features on command line (['']), but only added 0 (set()).  Did you add code to params.py's load_buzzer to actually add the feature to the buzzer?  Or did you forget to increment features_added in that function?
    INFO:root:Read 50 questions
    100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 118416.26it/s]
    INFO:root:Building guesses from dict_keys(['Gpr'])
    INFO:root:Generating guesses for 401 new question
    100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401/401 [00:00<00:00, 501166.84it/s]
    INFO:root:       401 guesses from Gpr
    INFO:root:Generating all features
    100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401/401 [00:00<00:00, 54978.95it/s]
    Ran on 50 questions of 50

If you get a warning about convergence, it is okay; hopefully it will converge better with more features!  Likewise, don't worry about the warning about the features, I just wanted to be sure it didn't add the length feature.  Because we want to do that next: train a model *with* that new feature.  Note that we're naming the model something different:

    python3 buzzer.py --guesser_type=Gpr --limit=50 \
      --GprGuesser_filename=../models/buzztrain_gpr_cache \
      --questions=../data/qanta.buzztrain.json.gz --buzzer_guessers Gpr \
      --LogisticBuzzer_filename=models/with_length --features Length
    Setting up logging
    INFO:root:Using device 'cuda' (cuda flag=False)
    INFO:root:Initializing guesser of type Gpr
    INFO:root:Loading Gpr guesser
    Loading buzzer
    INFO:root:Buzzer using run length 100
    INFO:root:Using device 'cuda' (cuda flag=False)
    INFO:root:Initializing guesser of type Gpr
    INFO:root:Loading Gpr guesser
    INFO:root:9310 entries added to cache
    INFO:root:9310 entries added to cache
    INFO:root:Adding Gpr to Buzzer (total guessers=1)
    Initializing features: ['Length']
    dataset: ../data/qanta.buzztrain.json.gz
    INFO:root:Adding feature Length
    INFO:root:Read 50 questions
    100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 118751.53it/s]
    INFO:root:Building guesses from dict_keys(['Gpr'])
    INFO:root:Generating guesses for 401 new question
    100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401/401 [00:00<00:00, 499084.84it/s]
    INFO:root:       401 guesses from Gpr
    INFO:root:Generating all features
    100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 401/401 [00:00<00:00, 46940.24it/s]
    Ran on 50 questions of 50


Now you need to evaluate the classifier.  The script eval.py will run the classifier on all of your data and then record the outcome.  There are several things that could happen:
 * _best_: Guess was correct, Buzz was correct
 * _timid_: Guess was correct, Buzz was not
 * _aggressive_: Guess was wrong, Buzz was wrong
 * _waiting_: Guess was wrong, Buzz was correct


Let's compare with the Length:

    python3 buzzer.py --guesser_type=Gpr --limit=50 \
    --GprGuesser_filename=../models/buzztrain_gpr_cache \
    --questions=../data/qanta.buzztrain.json.gz --buzzer_guessers Gpr \
    --features Length Frequency

compared to without it:

    .venv/bin/python3  eval.py --guesser_type=Gpr \
    --TfidfGuesser_filename=models/TfidfGuesser --limit=25 \
     --questions=../data/qanta.buzzdev.json.gz --buzzer_guessers Gpr \
     --GprGuesser_filename=../models/buzzdev_gpr_cache  \
     --LogisticBuzzer_filename=models/no_length --features ""

You'll see quite a bit of output, so I'm just going to walk through it bit by
    bit, comparing the salient components.

 Now, both "best" and "waiting" are *correct*, but obviously "best" is best.  It's important to know what kind of examples contribute to each of these outcomes, so eval samples a subset for each of these and prints them and their features out.

    =================
    aggressive 0.22
    ===================

                   guess: The Awakening (Chopin novel)
                  answer: Edna_Pontellier
                      id: 93160
          Gpr_confidence: -0.1257
             Length_char: -0.1111
             Length_word: -0.1333
            Length_guess: 3.3673
                    text: This character faintheartedly commits herself to improving her studies
                          after a night of reading Emerson alone in her house, and hushes Victor
                          when he begins singing "Ah! Si tu savais!" While talking to a friend,
                          she declares that she would give up the "unessential things" for her
                          children, but she wouldn't give herself up. Doctor Mandelet advises
                          this character's husband to permit her whims, which

This example is where it is answering the name of the novel rather than the book's main character.  You can see all of the features for this example (e.g., Length-guess is 3.3673).

At the end of the eval script, you can see the
overall accuracy, and the ratio of correct buzzes to incorrect buzzes (should
be positive), and the buzz position (where in the question it's buzzing).

    Questions Right: 90 (out of 201) Accuracy: 0.75  Buzz ratio: 67.50 Buzz position: 0.054159

And now we'll see what it is without the length features:

    Questions Right: 87 (out of 201) Accuracy: 0.76  Buzz ratio: 66.50 Buzz position: -0.255239

Again, don't focus too much on the accuracy.  The accuracy is actually higher
for the no feature model!  But the proportion of "Best" outcomes is higher by
0.02 once you add in this simple feature.

At the very end of the script, you see the weights of each of the features.  Higher values mean that when the feature is high, it is more likely to buzz.  Lower features mean that when the feature is high, it is less likely to buzz.  Features near zero are ignored.  However, keep in mind the average value of the feature ... I'd encourage you to keep your features with mean zero and standard variance to make your life easier.

Let's see with length:
                          Gpr_confidence: 4.4401
                             Length_char: 0.9581
                            Length_guess: -1.0036
                             Length_word: 0.8495
And without length:
                          Gpr_confidence: 5.5703

The classifier with the length is more liketly to buzz later in the question.  If you only have the guesser confidence, then it's obviously correlated with that.  It uses it less if you add in the length as a feature.

What Can You Do?
-

You can:
* Add features (e.g., to params.py)
* Change feature representations (e.g., features.py)
* Exclude data
* Add data

Good Enough
-
This is a very open-ended assignment.  Improve the "best" class by
at least 0.02 percent or improve the buzz ratio by 0.02 by adding new features, and you have done enough.

What Can't You Do?
-
Change the static guesses or use a different classifier (buzzer in this lingo).

How to start
-
1. Remind yourself how to run the sklearn logistic regression (logistic_buzzer.py)
2. Add a simple feature to the training data generated by gpr_guesser.py
3. See if it increases the accuracy on held-out data when you run logistic regression (eval.py) or on the leaderboard
4. Rinse and repeat!




Finding Correct Guesses (15+ points)
------------------------------

15 points of your score will be generated from your performance on the
the classification competition on the leaderboard.  The performance will be
evaluated on a held-out test set.  As discussed in more detail in the "good enough" section, we mostly care about increasing the proportion of "best" outcomes and improving the buzz ratio, and raw accuracy alone can be misleading.

You should be able to significantly
improve on the baseline system.  If you can
do much better than your peers, you can earn extra credit (up to 10 points).

Analysis (10 Points)
--------------

The job of the written portion of the homework is to convince the grader that:
* Your new features work
* You understand what the new features are doing
* You had a clear methodology for incorporating the new features

Make sure that you have examples and quantitative evidence that your
features are working well, and include the metrics you chose to measure your system's performance. Be sure to explain how used the data
(e.g., did you have a development set?) and how you inspected the
results.

A sure way of getting a low grade is simply listing what you tried and
reporting the corresponding metrics for each attempt.  You are expected to pay more
attention to what is going on with the data and take a data-driven
approach to feature engineering.

How to Turn in Your System
-
* ``features.py``: This file includes an implementation of your new features.
* ``params.py``: This instantiates your new features.  Modify this so that the
set of your best features runs by *default*.
* **Custom Training Data** (If you used additional training data beyond the Wikipedia pages, upload that as well
    * (OR) If either any of your files are >100MB, please submit a shell
    script named ``gather_resources.sh`` that will retrieve one or both of the
    files above programatically from a public location (i.e a public S3
    bucket).
* The LogisticBuzzer.model.pkl file and LogisticBuzzer.featurizer.pkl file created by training the classifier.
* ``analysis.pdf``: Your **PDF** file containing your feature engineering
analysis.

Turn in the above files as usual via Gradescope, where we'll be using the
leaderboard as before.  However, the position on the leaderboard will count
for more of your grade.

Checking the Cache
-----------------

If things aren't working well, you might have missing cache elements.  You can check if your cache "hits" enough by running this command:

    jbg:GPT3QA jordan$ .venv/bin/python3 gpr_guesser.py --cache=models/buzztrain_gpr_cache --source_jsongz=data/qanta.buzztrain.json.gz
    INFO:root:Loading 609173 questions and 609173 answers
    Loaded 18460 question
    Generating runs of length 100
    100%|███████████████████████████████| 18460/18460 [00:00<00:00, 42508.31it/s]
    ---------------------
    0.9840390879478828
    INFO:root:Hit ratio: 0.984039

It won't be 100 because OpenAI refuses to answer some of the questions, but it should be above 0.975.  Anything else is likely a problem and will likely result in lower accuracy.

FAQ
-----------------
**Q.: How can I improve the "waiting" category.**

**A.:** That's the neat thing, you don't.  If the guesser is wrong, then there's nothing you can do to make it correct (future homeworks won't have that problem).  What you can do is to convert "timid" to "best" and convert "aggressive" to "waiting".  

**Q. I get a ``No such file or directory: '../data/qanta.buzztrain.json.gz'`` when I run the code on Gradescope.**

*A.* Since the data directory is below where the code runs on Gradescope, Change the path to ``'./data/qanta.buzztrain.json.gz'`` in the ``features.add_training`` line.  If you find this annoying, you can use the following workarounds: (i) putting this into a try/except framework to work with either place, (ii) creating a symlink so so that ./data points to ../data on your development computer, (3) [first checking which path exists](https://docs.python.org/3/library/os.path.html) and then using the correct one.

**Q. Eval only shows me what the questions I'm getting right and wrong
are.  How do I know what the features look like?**

**A.** Use ``features.py`` to investigate this.  This is how we
generated the JSON files for the logistic regression homework.

    python3 features.py --json_guess_output=../data/inspect.jsonl --buzzer_guessers 'Gpr' --questions=../data/qanta.buzztrain.json.gz --limit=1000

Make sure that you've enabled all of the features that you want to use.

**Q. Why can't I use ``['page']`` or ``['answer']`` when creating
features?  Can I use it during training?**

**A.** Remember that we have multiple folds of the data, and we're using mostly buzztrain 
and buzzdev in this homework.  For those fields you cannot use "page" / "text" when
generating features for the example you're trying to decide whether or not to trust the guess,
as that would be cheating.  That's why they get removed
before the feature generator is called (in ``add_data`` in ``buzzer.py``) so that you cannot cheat.  If you need the current text
available, that's the "run", and your job is to see if the current
"guess" is correct or not.

Now, that's not to say that you can never use the page field.  You can use the field 
from *other* questions to better understand the distribution of answers, questions, etc.  You can see this
in the example Frequency feature: it uses the page to compute how
often each correct response is in the guesstrain fold.  You then check for a *guess* that comes
in how frequent it is in guesstrain; the intuition is that if the guess is more frequent,
it might be more likely to be an answer.  Or if something has never been an answer before,
maybe you should not risk it (and perhaps the relationship is non-linear, and you might need
to add cutoffs or thresholds ... hint, hint).

But that's the exception, usually the only way you would use the real
'page' during training on the buzzdev fold is as the label to the classifier: is this
guess correct becomes a positive example, is this guess incorrect
becomes a negative example.

**Q: Can I modify buzzer.py so that I can use the history of guesses in a
 question?**

**A:** Yes.  If you do that, make sure to upload buzzer.py.  We will replace the
 default version of buzzer.py with your new submission.

**Q: Can I use the <INSERT NAME HERE> package?**

**A:** Clear it first on Piazza.  We'll provide spacy and nltk for sure (along
 with all of the packages already used in this homework).  We
 won't allow packages that require internet access (e.g., wikipedia).  We
 don't have anything against Wikipedia (we provide this json file so you can
 use it), but we don't want to get our IP
 address banned.

**Q: Sometimes the guess is correct but it isn't counted that way.  And
 sometimes a wrong answer is counted as correct.**

**A:** Yes, and we'll cover this in more detail later in the course.  For now,
 this is something we'll have to live with.

**Q: What is the guesser that we're using?  Where are the guesses
coming from?**

**A:** These are cached guesses from OpenAI's GPT.  We'll get into
 generating our own guesses in the next homework.  You probably will
 want to play around a little bit with the output of its guesses, as
 there's likely interesting stuff you can use from there. Let's play
 around with the GprGuesser a little:


    >>> list(gg.cache.keys())[:3]
    ['The men in this work speak "of planting and rain, tractors and
    taxes". Some neighbors are denounced as a "pack of crazy old fools" to
    Mr. and Mrs. Adams by Old Man Warner. Earlier, Bobby Martin and Dickie
    Dell-a-croy are spotted playing, and some wooden chips were previously
    housed in Mr. Graves\' barn before being replaced by paper, as per the
    orders to the local coal entrepreneur. That character, Mr. Summers,
    later brings out a three-legged stool on June 27th and puts a black
    box on the stool. Townspeople like the Dunbars are relieved that they
    don\'t meet the fate of Tessie Hutchinson, who draws a slip of paper
    with a black spot on it. Name this short story in which Tessie is
    stoned to death as a result of the titular ritual, a work by Shirley
    Jackson.', 'One of the men depicted would die ten years later on the
    Gila River Indian Reservation after drinking', 'Men involved in this
    battle asked each other who Mickie Mouse\'s girlfriend was after the
    aggressors of this battle infiltrated enemy ranks and sabotaged
    progress in Operation Greif. In this battle, the Peipers, after
    capturing an enemy unit of 150 men, murdered 84 of them in an event
    known as the (*) Malmedy Massacre. The instigators of this offensive
    met fierce resistance in the city of Bastogne from a small force led
    by Brigadier General McAuliffe, who, when asked to surrender, cried
    "Nuts!" before being relieved by General Patton\'s Third Army. For ten
    points, name this last German offensive in the Ardennes, in which
    Adolf Hitler attempted to recapture Antwerp.']
    >>> question = list(gg.cache.keys())[0]
    >>> question
    'The men in this work speak "of planting and rain, tractors and taxes". Some neighbors are denounced as a "pack of crazy old fools" to Mr. and Mrs. Adams by Old Man Warner. Earlier, Bobby Martin and Dickie Dell-a-croy are spotted playing, and some wooden chips were previously housed in Mr. Graves\' barn before being replaced by paper, as per the orders to the local coal entrepreneur. That character, Mr. Summers, later brings out a three-legged stool on June 27th and puts a black box on the stool. Townspeople like the Dunbars are relieved that they don\'t meet the fate of Tessie Hutchinson, who draws a slip of paper with a black spot on it. Name this short story in which Tessie is stoned to death as a result of the titular ritual, a work by Shirley Jackson.'
    >>> gg(question)
    [{'guess': 'The Lottery', 'confidence': -0.0060731087}]

The keys are the prompts to GPT.  We've given GPT the closest examples
we can find in Wikipedia and from our existing dataset.

Let's take a look at what this returned.  We get the title, but that's
not all.  Remember that GPT is just a language model, so it generates
one word piece at a time, and we have a probability for each word
piece.

    >>> gg.cache[question]
    {'guess': 'The Lottery', 'confidence': [['The', -0.010978376], [' Lottery', -0.0011678414]]}

You may want to use these to create features beyoned the default of artithmetic average of the log probabilities!

**Q: What if I get the error that ``GprGuesser`` has no attribute 'predict'?**

**A:** This means that you're running it on a guesser result that hasn't been
 cached or that it can't find the cache file.  Make sure the path is correct,
 and use the limit option to only process a handful of examples.

 **Q: What's the intuition behind "buzz ratio"?**

**A:** It corresponds to how many points you get per question.  In the trivia community this is [points per tossup heard](https://www.naqt.com/stats/explanation.jsp#:~:text=For%20teams%2C%20PPTUH%20is%20the,an%20average%2020%2Dtossup%20game.).

**Q: Why do stupid features sometimes work?**

**A:** Features that sound stupid sometimes reveal something deeper.  For example, the length of the guess can be a proxy for GPT errors (e.g., it failed to complete its answer or didn't stop spewing content).

**Q: Why do clever features sometimes not work?**

**A:** Clever features might fail for several reasons: it's too infrequent, it's covered by another feature, it's not correlated with errors, or the feature value is not specified correctly.

_Infrequent_: All of this is a numbers game.  If your problem only appears in 1 out of 100 examples, then the gradients won't be large enough to move the feature value, which means that the feature won't have a big effect on overall predictions.

_Covered by Another Feature_: Remember that features only update when you have an error gradient.  If another feature captures the same phenomena perfectly ("correlated" if you remember this from 320), then the feature won't end up getting used.  And whatever feature is more frequent and covers more cases will get used ... all other features will be ignored.

_Not correlated with errors_: Like the above, if a system doesn't make a certain type of error, then a feature targeting that error, no matter how great, will not get used or be useful.  For example, if you create a feature that checks if a guess is consistent with a particular category won't be useful if the underlying guesser doesn't make cross-category errors.

_Not specified correctly_: One of the reasons that simple features that count stuff work well is that they are linear, one of the key assumptions of logistic regression.  If a feature value of 0.2 correlates with a good outcome, 1.1 correlates with bad outcomes, but 2.8 correlates with good outcomes again, then it's not going to be a good feature because it can't actually get encoded by a linear classifier.  You can address this by inspecting the distribution and creating threshold functions.

